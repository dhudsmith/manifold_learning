{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "from scipy.stats import ortho_group\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import numpy as np\n",
    "import math\n",
    "from time import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Data type: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# use nvidia gpu if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "# only float32 tested\n",
    "dtype = torch.float32\n",
    "    \n",
    "print(\"Device:\", device)\n",
    "print(\"Data type:\", dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Encoder/Decoder Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Norm(nn.Module):\n",
    "    \"\"\"L2Norm model class -- a layer class for normalizing a matrix of vectors\n",
    "    \n",
    "    Args:\n",
    "        dim (int) - which dimension to normalize along. 0 for column vectors, 1 for row vectors\n",
    "    \"\"\"\n",
    "    def __init__(self, dim=1):\n",
    "        super(L2Norm, self).__init__()\n",
    "        \n",
    "        self.dim=dim\n",
    "        \n",
    "    def forward(self,input):\n",
    "        return nn.functional.normalize(input, p=2, dim=self.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hamiltonian(nn.Module):\n",
    "    \"\"\"Hamiltonian -- a class used to help learn physically relevant sub-manifold\n",
    "    \n",
    "    Args:\n",
    "        H - the hamiltonian matrix in the original basis\n",
    "        N (int) - the size of the original basis\n",
    "        N_proj (int) - the size of the projected basis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, H, N, N_proj):\n",
    "\n",
    "        super(Hamiltonian, self).__init__()\n",
    "        \n",
    "        # initialize the class variables\n",
    "        self.H = H\n",
    "        self.N = N\n",
    "        self.N_proj = N_proj\n",
    "        self.eye = torch.eye(N_proj, device=device, dtype=dtype)\n",
    "        \n",
    "        # initialize the encoder and decoder architectures\n",
    "        self.decoder = nn.Sequential(OrderedDict([('matmul', nn.Linear(self.N_proj, self.N, bias=False)),\n",
    "                                                  ('normalize', L2Norm())\n",
    "                                                  ]))\n",
    "\n",
    "    # return the current cost matrix\n",
    "    def forward(self):\n",
    "        M = self.decoder(self.eye)\n",
    "        return M @ self.H @ M.t(), M @ M.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cost():\n",
    "    \"\"\"Cost class -- used to calculate goodness of projection map for optimization purposes\n",
    "    \n",
    "    Args:\n",
    "        N_proj - number of basis states in the projected space\n",
    "        alpha (float) - the weight of the orthogonality cost relative to the energy cost (units of energy)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, N_proj, alpha):\n",
    "        super(Cost, self).__init__()\n",
    "        \n",
    "        self.N_proj = N_proj\n",
    "        self.eye = torch.eye(N_proj, device=device, dtype=dtype)\n",
    "        self.sorter = torch.tensor([[1/(i+1)/(j+1) for i in range(self.N_proj)] for j in range(self.N_proj)], device=device, dtype=dtype)\n",
    "        \n",
    "    def __call__(self, Hproj, Iproj):\n",
    "        cost_matrix = (Hproj*self.sorter)**2 + alpha * (Iproj - self.eye)**2\n",
    "        return cost_matrix.sum()/self.N_proj**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesize a reasonable test Hamiltonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_H(N, N_proj):\n",
    "    eigs,_ = (torch.rand(N, device=device, dtype=dtype)*N).sort()\n",
    "    Hgen_proj = torch.diag(eigs)\n",
    "    Wgen = torch.tensor(ortho_group.rvs(N), device=device, dtype=dtype)\n",
    "    \n",
    "    Hgen = Wgen @ Hgen_proj @ Wgen.t()\n",
    "    \n",
    "    return Hgen, Wgen, eigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hamiltonian Setup\n",
    "N=500\n",
    "N_proj=30\n",
    "alpha=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigs: tensor([ 1.4541,  2.6655,  2.8721,  3.5421,  3.8253,  4.6797,  5.1546,  6.3272,\n",
      "         6.7771,  7.3475,  7.9243,  9.6975, 11.7525, 12.6057, 13.2221, 16.3810,\n",
      "        16.8727, 18.8439, 19.3214, 20.3303, 21.4008, 21.4098, 21.5786, 22.2389,\n",
      "        22.4583, 22.6910, 22.9431, 23.2577, 23.3700, 26.2989], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "Hgen, Wgen, eigs = generate_H(N, N_proj)\n",
    "print (\"eigs:\", eigs[:N_proj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.24 s, sys: 285 ms, total: 1.52 s\n",
      "Wall time: 543 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4541,  2.6655,  2.8721,  3.5420,  3.8253,  4.6797,  5.1546,  6.3271,\n",
       "         6.7771,  7.3478,  7.9242,  9.6974, 11.7524, 12.6057, 13.2221, 16.3809,\n",
       "        16.8726, 18.8438, 19.3213, 20.3303, 21.4008, 21.4098, 21.5785, 22.2390,\n",
       "        22.4583, 22.6910, 22.9430, 23.2577, 23.3699, 26.2989], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time torch.symeig(Hgen, eigenvectors=True).eigenvalues[:N_proj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the hamiltonian model\n",
    "model = Hamiltonian(Hgen, N, N_proj).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "criterion = Cost(N_proj, alpha)\n",
    "optimizer = optim.Rprop(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesize a physical Hamiltonian: two particles in a ring of length 1 (identical to a ring with a delta barrier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def physical_H(basis_size,g): # g for interaction strength, it is better if the basis_size is an odd number \n",
    "    H_data = g*np.ones((basis_size,basis_size)) # potential energy\n",
    "    H_diag=np.zeros(basis_size)\n",
    "    \n",
    "    for i in range(basis_size):\n",
    "        H_diag[i]= (2*math.pi*int(((i+1)/2)//1))**2 # kinetic energy E=k^2; k=2 Pi n, n=0,\\pm1 , \\pm 2,...\n",
    "    \n",
    "    H_phys =  torch.tensor(H_data+np.diag(H_diag),device=device, dtype=dtype)\n",
    "    \n",
    "    return H_phys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2.0000,   2.0000,   2.0000,   2.0000,   2.0000,   2.0000,   2.0000],\n",
       "        [  2.0000,  41.4784,   2.0000,   2.0000,   2.0000,   2.0000,   2.0000],\n",
       "        [  2.0000,   2.0000,  41.4784,   2.0000,   2.0000,   2.0000,   2.0000],\n",
       "        [  2.0000,   2.0000,   2.0000, 159.9137,   2.0000,   2.0000,   2.0000],\n",
       "        [  2.0000,   2.0000,   2.0000,   2.0000, 159.9137,   2.0000,   2.0000],\n",
       "        [  2.0000,   2.0000,   2.0000,   2.0000,   2.0000, 357.3058,   2.0000],\n",
       "        [  2.0000,   2.0000,   2.0000,   2.0000,   2.0000,   2.0000, 357.3058]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis_size=7\n",
    "g=2\n",
    "\n",
    "physical_H(basis_size,g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_stop(errs, rel_tol, patience=2):\n",
    "    stop=True\n",
    "    for i in range(patience):\n",
    "        rel_change = np.abs((errs[-(i+1)] - errs[-(i+2)]) / errs[-(i+1)])\n",
    "        stop = stop and rel_change < rel_tol\n",
    "    return stop\n",
    "\n",
    "def optimize(n_iter, n_save, show_progress=True, stop_early=True, rel_tol=0.01, patience=2):\n",
    "    model.decoder.matmul.reset_parameters()\n",
    "    running_loss= 0\n",
    "    start_time = time()\n",
    "    \n",
    "    # store progress every n_save iters\n",
    "    j=0\n",
    "    its = []\n",
    "    errs = []\n",
    "    Hps = []\n",
    "    Ips = []\n",
    "    ts = []\n",
    "    \n",
    "    # iterate\n",
    "    for i in range(n_iter):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        Hp, Ip = model()\n",
    "        loss = criterion(Hp, Ip)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print /save statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % n_save == 0:\n",
    "            # save progress\n",
    "            its.append(i)\n",
    "            errs.append(running_loss)\n",
    "            Hps.append(Hp)\n",
    "            Ips.append(Ip)\n",
    "            ts.append(time() - start_time)\n",
    "            \n",
    "            # print progress \n",
    "            if show_progress:\n",
    "                change = errs[j]-errs[j-1] if j>0 else 0\n",
    "                print('[%d] loss: %.8f. diff: %.8f. time: %.4f' % (i + 1, running_loss / 10, change, ts[-1]))\n",
    "            \n",
    "            if j>=patience and stop_early and early_stop(errs, rel_tol, patience):\n",
    "                print(\"Early stopping criteria met.\")\n",
    "                break\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            j+=1\n",
    "            \n",
    "\n",
    "    print('Finished Training')\n",
    "    return its, errs, Hps, Ips, ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping criteria met.\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "n_iter=1000\n",
    "n_print=1\n",
    "its, errs, hps, ips, ts = optimize(n_iter, n_print, stop_early=True, rel_tol=0.001, patience=3, show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hproj progress\n",
    "# vmax=eigs[:N_proj].abs().max()\n",
    "# vmin=0\n",
    "# for it, hp in zip(its,hps):\n",
    "#     Hplt = hp.cpu().detach().numpy()\n",
    "#     plt.imshow(np.abs(Hplt), origin=\"upper\", cmap='Spectral', interpolation=None, vmax=vmax, vmin=vmin)\n",
    "#     plt.title(\"iter: %i\" % (it+1))\n",
    "#     plt.colorbar()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(8,8, True)\n",
    "ax = plt.axes()\n",
    "vmax=eigs[:N_proj].abs().max()\n",
    "vmin=0\n",
    "Hplt = hps[0].cpu().detach().numpy()\n",
    "mat = plt.imshow(np.abs(Hplt), origin=\"upper\", cmap='Spectral', interpolation=None, vmax=vmax, vmin=vmin)\n",
    "\n",
    "\n",
    "def init():\n",
    "    mat.set_data(hps[0].cpu().detach().numpy())\n",
    "    return mat,\n",
    "def animate(i):\n",
    "    hp = hps[i].cpu().detach().numpy()\n",
    "    mat.set_data(hp)\n",
    "    return mat,\n",
    "\n",
    "anim = FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=len(hps), interval=60, blit=True)\n",
    "\n",
    "\n",
    "anim.save('diagonalization.gif', writer='imagemagick')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
